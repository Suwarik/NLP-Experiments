{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Shubham Warik\n",
        "CSE(DS)\n",
        "Roll No.:-66\n",
        "EXP-8"
      ],
      "metadata": {
        "id": "VeV779XUJFih"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXIzqWTXDrLU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sample data (context and senses)**"
      ],
      "metadata": {
        "id": "frK9OkXIDwot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    ([\"The\", \"bank\", \"by\", \"the\", \"river\", \"is\", \"steep.\"], \"financial_institution\"),\n",
        "    ([\"I\", \"walked\", \"along\", \"the\", \"river\", \"bank\", \"yesterday.\"], \"river_bank\"),\n",
        "]"
      ],
      "metadata": {
        "id": "qAsYyE0pD0FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Create a vocabulary**"
      ],
      "metadata": {
        "id": "PTUYae-uD2DV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(word for context, _ in data for word in context)\n",
        "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()}"
      ],
      "metadata": {
        "id": "tQDbvjoqD7xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Map sense labels to integers**"
      ],
      "metadata": {
        "id": "93wi6SghEd5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sense_labels = list(set(label for _, label in data))\n",
        "sense_to_idx = {sense: idx for idx, sense in enumerate(sense_labels)}\n",
        "idx_to_sense = {idx: sense for sense, idx in sense_to_idx.items()}"
      ],
      "metadata": {
        "id": "nAjP7UjVEc__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert data to tensors**"
      ],
      "metadata": {
        "id": "boR0LQKMD8hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_tensors = [(torch.tensor([word_to_idx[word] for word in context]), torch.tensor(sense_to_idx[sense])) for context, sense in data]"
      ],
      "metadata": {
        "id": "-QlNZLpqEDJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the LSTM-based WSD model**"
      ],
      "metadata": {
        "id": "NuRgAveFECuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WSDModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, sense_count):\n",
        "        super(WSDModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, sense_count)\n",
        "\n",
        "    def forward(self, context):\n",
        "        embedded = self.embedding(context)\n",
        "        lstm_out, _ = self.lstm(embedded.view(len(context), 1, -1))\n",
        "        prediction = self.fc(lstm_out[-1])\n",
        "        return prediction"
      ],
      "metadata": {
        "id": "LNdYHlIkEyTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameters**"
      ],
      "metadata": {
        "id": "hSVvh8rLE0kN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 100\n",
        "hidden_dim = 64\n",
        "sense_count = len(sense_labels)\n",
        "learning_rate = 0.001\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "9NFnd5fGE4Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialize the model**"
      ],
      "metadata": {
        "id": "HOG5pKnrE_a2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = WSDModel(vocab_size, embedding_dim, hidden_dim, sense_count)"
      ],
      "metadata": {
        "id": "PSTpxrd3FCFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the loss function and optimizer**"
      ],
      "metadata": {
        "id": "FUBA8SdbFGSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Ravju7m9FLdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training loop**"
      ],
      "metadata": {
        "id": "i7hSSLjVFN_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data, criterion, optimizer, epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for context, target_sense in data:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(context)\n",
        "            loss = criterion(output, target_sense.unsqueeze(0))  # Add batch dimension to target\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(data)}\")"
      ],
      "metadata": {
        "id": "JyS_GYONFRHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model**"
      ],
      "metadata": {
        "id": "FqhdWV34FXyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, data_tensors, criterion, optimizer, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doI8TFdLFZRc",
        "outputId": "5c355310-9d59-4bb7-8d78-5a77c09a8441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.6827487647533417\n",
            "Epoch 2/10, Loss: 0.5699001252651215\n",
            "Epoch 3/10, Loss: 0.48105157911777496\n",
            "Epoch 4/10, Loss: 0.40250203013420105\n",
            "Epoch 5/10, Loss: 0.3333987593650818\n",
            "Epoch 6/10, Loss: 0.27341802418231964\n",
            "Epoch 7/10, Loss: 0.22217873483896255\n",
            "Epoch 8/10, Loss: 0.1791478469967842\n",
            "Epoch 9/10, Loss: 0.14362745732069016\n",
            "Epoch 10/10, Loss: 0.11478246375918388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference (predict senses for new contexts)**"
      ],
      "metadata": {
        "id": "cfDpWW5oFcUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    new_context = [\"The\", \"bank\", \"charges\", \"high\", \"fees.\"]\n",
        "    new_context = torch.tensor([word_to_idx.get(word, 0) for word in new_context])\n",
        "    new_context = new_context.unsqueeze(0)  # Add batch dimension\n",
        "    predictions = model(new_context)\n",
        "    predicted_label = idx_to_sense[torch.argmax(predictions).item()]\n",
        "    print(f\"Predicted sense: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS9oVhfbFfgN",
        "outputId": "f0f7a9ce-6f7f-4d49-a3e7-0ad034de411c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted sense: financial_institution\n"
          ]
        }
      ]
    }
  ]
}